# Kiến trúc AI "Tối Thượng" cho Thiết Bị Biên (M.A.R.S Eternal v3)

## Tổng quan

Trong bối cảnh IoT, xe tự hành và các thiết bị biên tính toán hạn chế, nhu cầu về một kiến trúc AI **hoạt động hoàn toàn tại biên với hiệu năng cao** đang trở nên cấp thiết. Việc xử lý và học trên thiết bị cục bộ giúp tránh độ trễ và chi phí truyền dữ liệu khi phụ thuộc vào đám mây[\[1\]](https://arxiv.org/html/2403.04759v1#:~:text=On,and%20lightweight%20learning%20paradigm%20called). Thay vì mô hình tĩnh chỉ suy luận, hệ thống cần khả năng **học liên tục suốt vòng đời** sau khi triển khai, cho phép thích ứng với môi trường luôn biến đổi và ra quyết định thời gian thực ngay cả khi **không có kết nối mạng**[\[2\]](https://arxiv.org/html/2403.04759v1#:~:text=To%20fundamentally%20address%20these%20issues%2C,representing%20the%20future%20of%20IoT). Tuy nhiên, để đạt được điều này, mô hình phải giải quyết đồng thời nhiều thách thức:

* **Hiệu năng trên phần cứng hạn chế:** Bảo đảm mô hình chạy mượt với tài nguyên tính toán và bộ nhớ rất thấp (ví dụ vi điều khiển vài trăm KB).

* **Học liên tục, tránh quên:** Cập nhật tri thức từ luồng dữ liệu mới mà không làm “quên thảm họa” kiến thức cũ.

* **Thuần túy tại biên:** Mọi học tập và suy luận diễn ra tại thiết bị, không dựa vào máy chủ đám mây.

* **Suy luận nhân quả:** Hiểu và khai thác mối quan hệ nhân quả, tránh nhầm lẫn giữa tương quan ngẫu nhiên và quan hệ nguyên nhân \- kết quả thật sự.

* **Thích ứng thời gian thực:** Khi môi trường hoặc phân phối dữ liệu thay đổi đột ngột, hệ thống có thể tự điều chỉnh mô hình ngay khi suy luận (test-time adaptation).

* **Độ tin cậy trong môi trường khắc nghiệt:** Hoạt động ổn định trước nhiễu, dữ liệu thiếu hụt, hay kết nối không ổn định.

Những năm gần đây, hàng loạt xu hướng nghiên cứu từ NeurIPS, ICLR, ICML, CVPR đến TinyML đã manh nha các giải pháp cho từng khía cạnh trên. Các hướng tiếp cận như **tính toán siêu chiều (Hyperdimensional Computing \- HDC)**, **chưng cất dữ liệu (dataset distillation)**, **tối ưu hóa không dùng gradient**, **điều chuẩn phổ (spectral regularization)**, **bộ điều hợp động/LoRA** và **mô hình nhân quả** đang nổi lên. Chúng mở ra khả năng kết hợp trong một kiến trúc AI “tối thượng” chạy hoàn toàn cục bộ. Mục tiêu của thiết kế M.A.R.S Eternal v3 là hợp nhất những tiến bộ mới nhất này thành một kiến trúc tối ưu, đáp ứng đầy đủ các tiêu chí đề ra.

## Thành phần kiến trúc

Kiến trúc đề xuất bao gồm nhiều thành phần chuyên trách, phối hợp nhịp nhàng để đạt hiệu quả cao trong khuôn khổ tài nguyên hạn chế:

* **Mô hình nền hiệu năng cao:** Đây là mô-đun xử lý chính, gồm một mạng neural gọn nhẹ (ví dụ: các mô hình TinyML, MobileNet cực nhỏ) được **tối ưu hóa về lượng tử hóa và kiến trúc** để suy luận nhanh với CPU/MCU yếu. Mạng nền đảm nhiệm trích xuất đặc trưng đầu vào (âm thanh, hình ảnh, tín hiệu sensor...) và đưa ra dự đoán ban đầu. Kích thước mô hình được nén tối đa nhờ kỹ thuật distillation mô hình và thiết kế chuyên dụng cho thiết bị biên.

* **Bộ nhớ phân tán siêu chiều (HDC Memory):** Thành phần bộ nhớ cảm hứng từ **Hyperdimensional Computing** lưu trữ các **vector siêu chiều phân cực thấp** đại diện cho mẫu tri thức đã học. Cụ thể, hệ thống dùng mã hóa HDC để chuyển dữ liệu hoặc đặc trưng thành vector độ chiều cao, sau đó **ghi nhớ** chúng trong một bộ nhớ phân cấp. LifeHD (2024) đã chứng minh hiệu quả của cách tiếp cận này: họ tổ chức bộ nhớ hai tầng lưu các vector siêu chiều (HV) độ chính xác thấp làm tâm cụm, đại diện cho các mẫu lịch sử[\[3\]](https://arxiv.org/html/2403.04759v1#:~:text=organization%20to%20intelligently%20store%20and,Our%20code%20is%20available%20at). Cách lưu trữ này cho phép mô hình **ghi nhớ và truy xuất mẫu cũ một cách gọn nhẹ**, giảm thiểu hiện tượng “quên” trong môi trường dữ liệu dòng chảy. Nhờ HDC, LifeHD đạt độ chính xác phân cụm không giám sát tăng tới **74,8%** so với phương pháp học suốt đời dùng mạng neural trước đó, đồng thời **hiệu quả năng lượng gấp \~34 lần** giải pháp baseline[\[4\]](https://arxiv.org/html/2403.04759v1#:~:text=perform%20extensive%20evaluations%20across%20three,com%2FOrienfish%2FLifeHD). Điều này khẳng định bộ nhớ HDC vừa **bền vững với nhiễu**, vừa **tiết kiệm tài nguyên** vượt trội.

* **Kho dữ liệu chưng cất (Distilled Data Repository):** Để hỗ trợ học liên tục mà không cần lưu toàn bộ dữ liệu cũ, kiến trúc tích hợp một cơ chế **dataset distillation**. Cơ chế này tạo ra một tập dữ liệu tổng hợp nhỏ (như một số **mẫu đại diện được “cô đọng”** từ dữ liệu đã qua) và lưu trữ chúng trong bộ nhớ. Mỗi khi mô hình học xong một nhiệm vụ hoặc phân đoạn dữ liệu, một lượng nhỏ mẫu **được chưng cất** sẽ tóm tắt kiến thức của phân đoạn đó. Những “mẫu chưng cất” này đóng vai trò như **kinh nghiệm nén**: khi học nhiệm vụ mới, mô hình có thể hồi tưởng lại nhiệm vụ cũ bằng cách luyện tập trên các mẫu tổng hợp này, thay vì cần truy xuất dữ liệu gốc. Kỹ thuật này đã được chứng minh giúp giảm quên thảm họa trong học liên tục – các tập dữ liệu được chưng cất tóm tắt tác vụ cũ và **giúp mô hình duy trì hiệu năng trên tác vụ trước khi học thêm tác vụ mới**[\[5\]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/#:~:text=,2022). Thành phần này đảm bảo **hạn chế tối đa việc quên** mà không tốn nhiều bộ nhớ (vì chỉ lưu rất ít dữ liệu).

* **Mô-đun cập nhật không cần gradient:** Một thách thức khi huấn luyện trên thiết bị biên là quá trình tính gradient (lan truyền ngược) tiêu tốn tài nguyên và đôi khi không khả thi (ví dụ mô hình nhúng đen hộp hoặc phần cứng không hỗ trợ). Do đó, kiến trúc bao gồm cơ chế **tối ưu hóa phi gradient** cho các bước cập nhật nhanh. Thay vì tinh chỉnh mô hình bằng SGD/Adam truyền thống, mô-đun này sử dụng các thuật toán dựa trên **lan truyền thuận nhiều lần** (ví dụ: ước lượng gradient bậc zero, evolution strategy hoặc các quy tắc Hebb) để hiệu chỉnh mô hình. Nghiên cứu ZeroFlow (ICML 2025\) cho thấy chỉ sử dụng **forward pass** cũng có thể đủ để mô hình thích nghi mà không quên kiến thức cũ: thậm chí **các phương pháp chỉ dựa trên lan truyền thuận có thể giảm thiểu đáng kể quên thảm họa**, mở ra tiềm năng lớn cho tối ưu hóa phi gradient trong bối cảnh học liên tục[\[6\]](https://arxiv.org/html/2501.01045v4#:~:text=hardware%20constraints%2C%20or%20non,new%20enhancements%20that%20further%20improve). Với thành phần này, thiết bị biên có thể **học nhanh trong điều kiện hạn chế**, nơi mà việc tính đạo hàm phức tạp bị “cấm” hoặc không khả thi.

* **Bộ điều hợp động (Dynamic Adapters/LoRA):** Khi cần **học thông tin mới mà không làm xáo trộn mạng nền**, kiến trúc tận dụng các **adapter linh hoạt**, tiêu biểu như **Low-Rank Adaptation (LoRA)**. Thay vì cập nhật toàn bộ trọng số mạng nền (dễ gây quên), hệ thống gắn thêm các **mô-đun nhỏ** (ví dụ ma trận trọng số xếp hạng thấp) vào mô hình. Mỗi khi một nhiệm vụ hoặc ngữ cảnh mới xuất hiện, một adapter mới (với vài thông số) được huấn luyện nhanh để hấp thụ kiến thức mới, trong khi **trọng số chính của mô hình được cố định** hoặc thay đổi rất ít. Điều này tương tự cách LLMs lớn được tùy biến bằng LoRA – rất hiệu quả về tham số và **hạn chế làm suy giảm kiến thức nền】. Các nghiên cứu gần đây cho thấy phương pháp fine-tune hiệu quả tham số như LoRA** đang được chú ý vì khả năng khắc phục quên thảm họa với chi phí huấn luyện rất nhẹ[**\[7\]**](https://arxiv.org/html/2505.11998v3#:~:text=Catastrophic%20forgetting%20has%20remained%20a,dynamic%20rank%20allocation%20for%20LoRA)**. Đặc biệt, kỹ thuật** thích ứng hạng thấp động **(dynamic rank adaptation) cho phép tự điều chỉnh kích thước adapter tùy độ phức tạp của tác vụ, đạt cân bằng giữa “nhớ và quên”. Ví dụ, khung PEARL (2025) sử dụng LoRA động đã** vượt trội tất cả baseline **về học liên tục trên nhiều kiến trúc thị giác, cho thấy thêm adapter một cách thông minh có thể duy trì hiệu năng các tác vụ cũ trong khi tiếp thu cái mới[\[8\]](https://arxiv.org/html/2505.11998v3#:~:text=knowledge%20in%20pre,ResNet%2C%20Separable). Bộ điều hợp động trong kiến trúc M.A.R.S Eternal v3 đóng vai trò như “não phụ trợ” cho mỗi nhiệm vụ/ngữ cảnh:** dễ dàng mở rộng kiến thức mới mà không ảnh hưởng mô-đun cũ\*\*, nhờ đó tránh được can thiệp lẫn nhau giữa các nhiệm vụ.

* **Mô-đun suy luận nhân quả:** Để đạt khả năng **ra quyết định đáng tin cậy trong môi trường phức tạp**, kiến trúc tích hợp một thành phần chuyên thực hiện suy luận nhân quả. Mô-đun này có thể được thiết kế dưới dạng một **mô hình nhân quả cấu trúc** song song với mạng nền, hoặc nhúng trực tiếp các ràng buộc nhân quả vào quá trình học sâu. Ý tưởng là trang bị cho hệ thống hiểu biết về **quan hệ nhân \- quả giữa các biến** (ví dụ giữa sự kiện và cảm biến, giữa hành động và kết quả) thay vì chỉ học mỗi tương quan thống kê. Xu hướng **Neural Causal Models (NCM)** cho thấy việc kết hợp mạng nơ-ron với mô hình nhân quả giúp vừa **mô hình hóa linh hoạt dữ liệu phức tạp**, vừa cho phép **suy luận can thiệp và phản nhân quả một cách nguyên tắc** dựa trên đồ thị nhân quả ngầm[\[9\]](https://www.emergentmind.com/topics/neural-causal-models-ncms#:~:text=typically%20feedforward%20multilayer%20perceptrons,and%20empirical%20results%20regarding%20NCMs). Trong bối cảnh IoT thực tế, thành phần này giúp hệ thống **phân biệt được tín hiệu nhân quả thật và nhiễu tương quan giả**, tăng độ bền vững. Chẳng hạn, một hệ thống nhà thông minh có thể nhận ra việc máy pha cà phê và lò nướng bánh cùng bật buổi sáng chỉ là hiện tượng đồng thời, không nên suy diễn chiếc này gây ra chiếc kia; nếu không, mô hình sẽ dễ nhầm lẫn và thất bại khi chỉ một thiết bị hoạt động[\[10\]](https://arxiv.org/html/2509.06483v1#:~:text=smart%20home%2C%20a%20single%20human,robustness%2C%20making%20it%20liable%20to). Do đó, mô-đun nhân quả được dùng để giám sát và hiệu chỉnh nhận thức của mạng nền: mỗi quyết định đều được “kiểm tra” dưới lăng kính nhân quả (dựa trên tri thức đã học hoặc đồ thị causality nội tại). Một số thiết kế gần đây còn đề xuất **học đồ thị nhân quả trực tiếp từ dữ liệu** và dùng nó làm tri thức tiên nghiệm dẫn dắt mô hình dự đoán[\[11\]](https://arxiv.org/html/2509.06483v1#:~:text=that%20evolve%20based%20on%20data,lack%20of%20a%20unified%20framework) – kiến trúc của chúng tôi cũng hướng tới khả năng này. Tóm lại, thành phần nhân quả bảo đảm hệ thống không chỉ **phản ứng thụ động** theo mẫu huấn luyện, mà còn **suy luận có hiểu biết**, ứng phó tốt hơn với các tình huống bất ngờ trong thế giới thực.

* **Cơ chế thích ứng khi suy luận (Test-Time Adaptation):** Đây là thành phần cho phép mô hình **tự điều chỉnh tham số “nóng” ngay lúc vận hành** để thích nghi tức thì với dữ liệu đầu vào thay đổi. Cơ chế này đặc biệt hữu dụng khi thiết bị di chuyển sang môi trường mới hoặc cảm biến gặp điều kiện ngoại lai (nhiễu, thời tiết, ánh sáng khác thường...). Thay vì chấp nhận suy giảm độ chính xác, mô-đun TTA sẽ tiến hành một số bước hiệu chỉnh ngắn trên mô hình dựa trên tín hiệu không nhãn (như cực tiểu hóa entropy đầu ra, tối ưu thống kê batch norm, hoặc tự luyện với dự đoán có độ tin cậy cao của chính mô hình). Kiến trúc đề xuất tích hợp một **engine TTA gọn nhẹ** tối ưu cho MCU. Gợi ý từ TinyTTA (NeurIPS 2024\) cho thấy có thể thực hiện TTA ngay trên vi điều khiển bằng cách dùng chiến lược ensemble nội tại và **cắt ngắn mạng** (early-exit) để giảm tải tính toán[\[12\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=sizes,with%20small%20batch%20sizes%20for). Nhờ vậy, mô hình có thể cập nhật với batch size cực nhỏ (thậm chí từng mẫu một) mà **không cần nhiều bộ nhớ**, vẫn cải thiện được độ chính xác khi phân phối dữ liệu thay đổi. Thực nghiệm TinyTTA chỉ ra rằng triển khai TTA trực tiếp trên thiết bị hạn chế đem lại kết quả ấn tượng: độ chính xác cải thiện tới **57,6%**, sử dụng bộ nhớ giảm 6 lần, và tăng tốc độ suy luận đáng kể; đặc biệt, đây là giải pháp **đầu tiên chạy được TTA trên vi điều khiển 512KB RAM** (STM32) mà vẫn giữ hiệu năng cao[\[13\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=Moreover%2C%20we%20develop%20the%20TinyTTA,devices%2C%20such%20as%20microcontroller%20units). Trong kiến trúc của chúng tôi, module TTA sẽ giám sát luồng dữ liệu vào; nếu phát hiện độ lệch phân phối (ví dụ qua độ tăng entropy dự đoán), nó sẽ kích hoạt quy trình thích ứng (với các kỹ thuật như trên) để **điều chỉnh mô hình “tại chỗ”**. Quá trình này hoàn toàn tự động và nhanh, đảm bảo hệ thống **phục hồi độ chính xác trong thời gian thực** khi môi trường thay đổi.

Tóm lại, kiến trúc M.A.R.S Eternal v3 gồm một **mô hình nền nhỏ gọn** phối hợp với **bộ nhớ HDC**, **kho dữ liệu chưng cất**, **cập nhật phi gradient**, **adapter động LoRA**, **mô-đun nhân quả** và **engine thích ứng tức thời**. Mỗi thành phần giải quyết một mặt của bài toán, đồng thời tích hợp thành một thể thống nhất để tạo nên một AI biên toàn diện: **vừa nhẹ, vừa thông minh thích nghi, vừa đáng tin cậy**.

## Luồng hoạt động

Kiến trúc trên vận hành qua các bước liên hoàn, đảm bảo việc **xử lý tín hiệu, suy luận và học tập diễn ra liên tục** trên thiết bị:

1. **Tiếp nhận và xử lý đầu vào:** Dữ liệu thô từ cảm biến (ví dụ camera, micrô, lidar, cảm biến chuyển động...) được đưa vào mô hình nền. Mạng nền thực hiện tiền xử lý và trích xuất đặc trưng gọn nhẹ phù hợp với tài nguyên (như tính toán các feature map kích thước nhỏ). Kết quả ban đầu là **đầu ra mô hình nền** (vd: phân loại khung hình, phát hiện vật cản, v.v.).

2. **Suy luận và kiểm tra nhân quả:** Đầu ra mô hình nền ngay lập tức được **mô-đun nhân quả** kiểm tra chéo nếu có thể. Thành phần nhân quả đánh giá xem dự đoán có phù hợp với các quan hệ nhân quả đã biết hay không. Trong nhiều trường hợp, mô-đun này có thể hiệu chỉnh quyết định cuối cùng: ví dụ, nếu mô hình nền báo động "hỏng cảm biến" nhưng theo quan hệ nhân quả thì nguyên nhân có thể do nhiệt độ giảm đột ngột, hệ thống sẽ kiểm tra thêm cảm biến nhiệt trước khi kết luận. Việc này giúp giảm các **phán đoán sai do nhiễu hoặc trùng hợp ngẫu nhiên**, nâng cao độ tin cậy.

3. **Thích ứng nhanh trong quá trình suy luận:** Nếu môi trường hiện tại có **dấu hiệu thay đổi so với lúc huấn luyện** (ví dụ camera bị mờ hoặc ánh sáng yếu làm phân phối pixel lệch đi), **engine TTA** sẽ kích hoạt. Hệ thống gom một nhóm nhỏ mẫu đầu vào gần nhất và thực hiện hiệu chỉnh tham số online. Cụ thể, có thể dùng kỹ thuật *entropy minimization* (giảm độ hỗn loạn của phân phối dự đoán) hoặc *batch norm adaptation* để điều chỉnh thống kê lớp chuẩn hóa cho phù hợp dữ liệu mới. Trên các thiết bị có hỗ trợ, engine TTA có thể dùng chiến lược **early-exit**: mô hình có nhiều điểm dừng sớm, cho phép dừng suy luận ở tầng thích hợp nếu đã đủ tự tin, tiết kiệm tính toán. Sau một vài bước lan truyền *forward* với tự học ngắn, mô hình được **tái hiệu chỉnh ngay lập tức**. Nhờ đó, đầu ra dự đoán được cập nhật cho sát với môi trường hiện thời hơn (ví dụ, cải thiện đáng kể độ chính xác phân loại trong điều kiện ánh sáng khác thường như đã chứng minh ở TinyTTA[\[13\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=Moreover%2C%20we%20develop%20the%20TinyTTA,devices%2C%20such%20as%20microcontroller%20units)). Quá trình này diễn ra nền trong khi hệ thống vẫn đáp ứng thời gian thực.

4. **Phát hiện và cập nhật kiến thức mới:** Khi gặp một **mẫu hoặc sự kiện hoàn toàn mới** (ví dụ: mô hình nhận dạng được một loại đối tượng chưa từng thấy, hoặc sensor xuất hiện một trạng thái lạ), hệ thống sẽ ghi nhận **tín hiệu bất thường** qua cơ chế novelty detection. Lúc này, quy trình **học liên tục** được khởi động:

5. Đầu tiên, mô-đun HDC tạo một **vector siêu chiều** đại diện cho mẫu mới đó và tạm lưu vào **bộ nhớ làm việc**. Nếu mẫu này lặp lại và hình thành một khái niệm mới (ví dụ một class mới), các vector tương ứng sẽ được **gộp cụm** và sinh ra **trung tâm cụm HV mới**. Bộ nhớ HDC qua đó tự mở rộng để bao quát tri thức mới mà **không làm mất** các vector cũ (theo cơ chế hai tầng: bộ nhớ ngắn hạn và dài hạn như LifeHD đề xuất[\[14\]](https://arxiv.org/html/2403.04759v1#:~:text=match%20at%20L586%20consolidated%20to,term%20memory)). Khi số lượng mẫu tăng vượt ngưỡng, mô-đun áp dụng chính sách **quên có điều khiển**: ví dụ loại bỏ những HV lâu không dùng nhất (cơ chế LRU) hoặc gộp các HV gần nhau, nhằm giới hạn dung lượng trong phạm vi cho phép[\[15\]](https://arxiv.org/html/2403.04759v1#:~:text=When%20reaching%20its%20size%20limit,term%20memory). Nhờ chiến lược này, kiến thức mới được thêm vào trong khi vẫn **duy trì các mẫu quan trọng cũ**, hạn chế quên thảm họa.

6. Song song, **kho dữ liệu chưng cất** cũng được cập nhật. Nếu mô hình nền vừa học xong một tập dữ liệu mới (dù nhỏ), một thuật toán distillation sẽ tạo ra một vài **mẫu tổng hợp** tiêu biểu cho tập đó và thêm vào kho. Ngược lại, nếu phải giải phóng bộ nhớ, hệ thống có thể thay thế một loạt dữ liệu cũ bằng **một vài mẫu distilled** mang lượng thông tin tương đương. Như vậy, khi cần ôn lại kiến thức cũ, mô hình chỉ việc huấn luyện trên các mẫu distilled này là đủ để lấy lại \~80-90% hiệu năng trên dữ liệu gốc[\[16\]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/#:~:text=performance%20while%20offering%20significant%20efficiency,discuss%20the%20significance%20of%20distillation)[\[5\]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/#:~:text=,2022). Điều này cực kỳ hữu ích vì thiết bị biên không thể lưu mọi dữ liệu đã thấy, nhưng với “tinh chất dữ liệu” thì vẫn không quên hoàn toàn nhiệm vụ cũ.

7. **Cập nhật mô hình nền và adapter:** Kiến thức mới sau khi mã hóa vào HDC hoặc distilled data sẽ được lan tỏa vào mô hình chính. Tùy trường hợp, hệ thống có thể chọn **huấn luyện một adapter LoRA mới** cho khái niệm vừa gặp thay vì đụng chạm mô hình nền. Chẳng hạn, khi xe tự hành gặp biển báo mới, một adapter nhỏ được thêm để nhận diện biển đó, còn mạng chính không thay đổi nhiều – đảm bảo các biển cũ vẫn nhận diện tốt (phương pháp này từng được chứng minh giảm quên rất hiệu quả[\[17\]](https://arxiv.org/html/2505.11998v3#:~:text=%28e.g.%2C%20%5Bkirkpatrick2017overcoming%5D%29%20and%20parameter,both%20economically%20and%20environmentally%20infeasible)). Nếu không dùng adapter, hệ thống sẽ **fine-tune nhẹ mô hình nền** trên sự kết hợp giữa dữ liệu mới và một ít mẫu hồi tưởng từ HDC memory hoặc distilled data (giống như phương pháp rehearsal). Trong bước fine-tune này, mô-đun **cập nhật phi gradient** có thể được sử dụng để tránh tính toán nặng: ví dụ áp dụng một vài **lần đệ quy lan truyền thuận** thử sai để điều chỉnh trọng số cho phù hợp với đầu ra mong muốn, thay vì backpropagation. Bên cạnh đó, kỹ thuật **điều chuẩn phổ** được áp dụng trong hàm loss nhằm **giữ cho mô hình còn khả năng học tiếp** mà không bị “đóng băng” sau nhiều lần huấn luyện[\[18\]](https://openreview.net/forum?id=Hcb2cgPbMg#:~:text=continual%20learning%20inspired%20by%20the,We%20present%20an%20experimental). Cụ thể, một hệ số regularization sẽ giới hạn giá trị riêng lớn nhất của mỗi lớp gần bằng 1, giúp duy trì độ đa dạng gradient và độ dốc loss ổn định khi học cái mới, tránh hiện tượng mô hình mất tính dẻo dai[\[19\]](https://openreview.net/forum?id=Hcb2cgPbMg#:~:text=beneficial%20initialization%20properties%20throughout%20training,demonstrating%20better%20training%20in%20individual). Kết thúc bước này, **mô hình nền được cập nhật** (hoặc mở rộng bởi adapter) để phản ánh cả kiến thức mới.

8. **Phản hồi và lặp lại:** Sau khi cập nhật, hệ thống tiếp tục vòng suy luận cho các dữ liệu mới đến. Nhờ kiến trúc đề xuất, mô hình ngày càng **giàu kinh nghiệm**: vừa nhận biết được nhiều tình huống hơn, vừa không quên nhiệm vụ ban đầu. Mọi quá trình từ suy luận, thích ứng nhanh, đến cập nhật kiến thức đều diễn ra **nội bộ trên thiết bị**, liên tục theo thời gian thực. Nếu ở giai đoạn nào đó, mô hình gặp **giới hạn tài nguyên** (ví dụ bộ nhớ HDC đầy hoặc quá nhiều adapter), hệ thống sẽ kích hoạt các cơ chế tối ưu như **gộp bớt cluster, nén bớt adapter** (dựa trên độ quan trọng) để tự điều chỉnh về trạng thái gọn nhẹ hơn. Qua mỗi chu kỳ như vậy, AI biên tiến gần hơn đến khả năng **tự trị hoàn toàn**: nó học hỏi không ngừng từ môi trường, thích nghi với thay đổi trong chớp mắt, và ra quyết định chuẩn xác dựa trên hiểu biết nhân quả – tất cả đều độc lập, không cần sự can thiệp từ đám mây.

## Ưu điểm kỹ thuật

Kiến trúc M.A.R.S Eternal v3 mang lại nhiều ưu điểm vượt trội về mặt kỹ thuật so với các giải pháp truyền thống:

* **Hiệu năng cao trên thiết bị hạn chế:** Nhờ thiết kế mô hình tinh gọn và tận dụng tính toán siêu chiều, hệ thống đạt hiệu quả suy luận và học tập xuất sắc ngay cả trên phần cứng yếu. Ví dụ, việc sử dụng HDC giúp tăng cường độ **bền bỉ với nhiễu và lỗi bit** (do vector siêu chiều có tính dư thừa, sai lệch nhỏ không ảnh hưởng kết quả), đồng thời giảm tiêu thụ năng lượng đáng kể. Kết quả đo đạc cho thấy phương pháp HDC có thể **nâng cao độ chính xác đến 70%+** so với mạng neural truyền thống trong kịch bản học không giám sát, trong khi **tiết kiệm năng lượng gấp hàng chục lần** trên thiết bị edge như Raspberry Pi và Jetson[\[4\]](https://arxiv.org/html/2403.04759v1#:~:text=perform%20extensive%20evaluations%20across%20three,com%2FOrienfish%2FLifeHD). Bản thân mô hình nền được nén qua distillation và adapter nên lượng tính toán giảm mạnh, đảm bảo **đáp ứng thời gian thực** (ví dụ nhận dạng sự kiện trong vài chục mili-giây trên MCU).

* **Học liên tục không quên kiến thức cũ:** Nhờ phối hợp bộ nhớ HDC và dataset distillation, kiến trúc lưu giữ được cốt lõi của dữ liệu cũ dưới dạng xúc tích nhất. Mỗi khi học nhiệm vụ mới, mô hình đều **ghi nhớ tóm tắt nhiệm vụ cũ** nên tránh được tình trạng “học cái mới quên cái cũ” vốn rất nan giải trong học liên tục. Tài liệu khảo sát gần đây cũng khẳng định cách **tóm tắt các tác vụ đã qua bằng dataset distillation giúp giảm hẳn hiện tượng quên thảm họa** khi mô hình học dần dần[\[5\]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/#:~:text=,2022). Hơn nữa, chiến lược sử dụng LoRA cho nhiệm vụ mới nghĩa là **thông tin cũ và mới tách biệt tương đối**, giảm giao thoa phá hoại. Mô hình nền được bảo vệ khỏi những thay đổi lớn nhờ regularization (EWC, spectral reg, v.v.), do đó **hiệu năng trên các tác vụ ban đầu hầu như giữ nguyên** sau nhiều lần cập nhật. So với các phương pháp SOTA trước đây phải hy sinh một phần hiệu năng cũ để học cái mới, kiến trúc này hướng tới **giữ vững hiệu năng mọi nhiệm vụ đã học**.

* **Thích ứng nhanh theo thời gian thực:** Khả năng test-time adaptation tích hợp giúp mô hình **tự hiệu chỉnh tức thì** mỗi khi dữ liệu vào có độ lệch. Trong điều kiện thực tế nhiều biến động (ánh sáng, tiếng ồn, thời tiết...), hệ thống duy trì độ chính xác cao mà **không cần con người can thiệp**. So với mô hình tĩnh phải chấp nhận giảm độ chính xác khi gặp dữ liệu khác phân phối, kiến trúc này có thể **khôi phục hàng chục phần trăm hiệu năng chỉ sau vài bước thích nghi ngắn hạn**[\[13\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=Moreover%2C%20we%20develop%20the%20TinyTTA,devices%2C%20such%20as%20microcontroller%20units). Điều này đặc biệt quan trọng cho các ứng dụng an toàn (xe tự lái, giám sát y tế), nơi mà mỗi % cải thiện độ chính xác đều đáng giá.

* **Hoạt động hoàn toàn cục bộ, độc lập:** Toàn bộ chu trình từ thu thập dữ liệu, suy luận, đến huấn luyện bổ sung đều diễn ra tại thiết bị biên. Điều này loại bỏ độ trễ do mạng, giảm rủi ro mất kết nối và **bảo vệ dữ liệu riêng tư** (vì dữ liệu thô không rời khỏi thiết bị). Hệ thống có thể triển khai theo kiểu *deploy-and-run* tại hiện trường: sau khi cài đặt là tự động vận hành, liên tục học từ mẫu mới mà **không cần đồng bộ về máy chủ trung tâm**. Nghiên cứu đã chỉ ra rằng phương thức **học suốt đời trên thiết bị** chính là tương lai của IoT, do nó cắt giảm nhu cầu thu thập dữ liệu tốn kém và cho phép **ra quyết định thời gian thực ngay cả khi offline**[\[2\]](https://arxiv.org/html/2403.04759v1#:~:text=To%20fundamentally%20address%20these%20issues%2C,representing%20the%20future%20of%20IoT). Về mặt bảo mật, việc không phụ thuộc cloud giúp tránh nguy cơ rò rỉ dữ liệu hoặc bị tấn công trong quá trình truyền.

* **Suy luận nhân quả nâng cao độ tin cậy:** Nhờ mô-đun nhân quả, hệ thống **hiểu sâu hơn về dữ liệu** thay vì chỉ dựa vào mẫu thống kê. Nó nhận biết những mối quan hệ ẩn quan trọng (ví dụ sự kiện A gây ra hiện tượng B) nên ra quyết định hợp lý hơn, tránh được những lỗi ngớ ngẩn trước tình huống bất thường. Điều này giúp mô hình **tổng quát hoá tốt hơn** sang môi trường mới – một yếu tố thường bị bỏ qua trong các mạng học sâu truyền thống. Chẳng hạn, khi một số cảm biến bị lỗi hoặc đưa thông tin sai lệch, hệ thống có thể dựa vào logic nhân quả để phán đoán nguyên nhân thực sự, thay vì phản ứng sai theo tín hiệu trực quan. Cách tiếp cận này mang lại **độ robust cao trong môi trường khắc nghiệt**, nơi dữ liệu thường nhiễu và thiếu.

* **Hiệu quả tham số và tài nguyên:** Kiến trúc tận dụng các phương pháp **hiệu quả tham số** (parameter-efficient) như LoRA, adapter, nhờ đó **số lượng tham số cần học thêm rất ít** so với mô hình gốc. Mỗi lần thích nghi hay mở rộng kiến thức chỉ thêm một lượng tham số nhỏ (vài % so với toàn bộ mô hình), do vậy tránh được việc mô hình phình to quá mức. Các nghiên cứu cho thấy đây là hướng đi bền vững: mô hình tiền huấn luyện lớn có thể liên tục được **fine-tune thông minh** bằng cách gắn kết các module nhỏ mà **tránh tăng nhiều footprint tính toán**[\[17\]](https://arxiv.org/html/2505.11998v3#:~:text=%28e.g.%2C%20%5Bkirkpatrick2017overcoming%5D%29%20and%20parameter,both%20economically%20and%20environmentally%20infeasible). Về lâu dài, hệ thống sẽ bao gồm một tập các “plugin kiến thức” có thể bật/tắt theo ngữ cảnh, thay vì một mô hình đơn khổng lồ. Kết hợp với tối ưu phi gradient (không đòi hỏi phần cứng tính toán ma trận lớn), giải pháp này thực sự **thân thiện với tài nguyên hạn chế và năng lượng**.

Tóm lại, kiến trúc M.A.R.S Eternal v3 mang lại **sự cân bằng tối ưu** giữa **tốc độ, độ chính xác, khả năng thích nghi và tiết kiệm tài nguyên**. Nó cho phép các thiết bị biên nhỏ bé đạt được hành vi thông minh phức tạp gần ngang tầm các hệ thống cloud, mở ra thế hệ AI nhúng **tự chủ và tin cậy hơn**.

## So sánh với SOTA hiện tại

Kiến trúc đề xuất vượt trội so với trạng thái nghệ thuật (SOTA) hiện nay trên nhiều phương diện, nhờ tích hợp các ưu điểm mà trước đây thường chỉ thấy tách rời trong các nghiên cứu riêng lẻ:

* **So với mô hình edge truyền thống (TinyML inference-only):** Phần lớn các giải pháp TinyML hiện nay chỉ tập trung vào **suy luận trên thiết bị** sau khi đã huấn luyện xong trên cloud, mô hình cố định và **không học thêm sau triển khai**[\[20\]](https://arxiv.org/html/2403.04759v1#:~:text=and%20Peng%2C%202022%20%29,adaptability%20to%20accommodate%20new%20environments). Điều này dẫn đến hạn chế là khi môi trường thay đổi hoặc xuất hiện đối tượng mới, mô hình **không có cách nào thích ứng** ngoài việc gửi dữ liệu về cloud để huấn luyện lại – mâu thuẫn với yêu cầu thời gian thực và tự chủ. Ngược lại, M.A.R.S Eternal v3 cho phép **học và thích nghi liên tục tại chỗ**, biến thiết bị biên thành một thực thể AI sống động thay vì chỉ là “máy tính bảng” thụ động. So với TinyML inference-only, kiến trúc chúng tôi **phức tạp hơn**, nhưng đổi lại giải quyết được bài toán mà TinyML truyền thống bỏ ngỏ: học suốt đời trên thiết bị.

* **So với giải pháp cloud-centric:** Cách tiếp cận truyền thống trong IoT là gửi dữ liệu lên đám mây để xử lý bằng mô hình lớn. SOTA dạng này cho kết quả tốt trong môi trường quen thuộc, nhưng **gặp vấn đề về độ trễ và phụ thuộc kết nối**. Hơn nữa, khi mất mạng hoặc băng thông thấp, hệ thống gần như tê liệt. Kiến trúc đề xuất **không cần đến đám mây**, do đó tránh được mọi nhược điểm trên[\[21\]](https://arxiv.org/html/2403.04759v1#:~:text=cities%C2%A0%28Chen%20et%C2%A0al,only). Về hiệu năng, nhờ tận dụng triệt để tài nguyên tại chỗ, hệ thống có thể phản ứng **nhanh hơn nhiều lần** so với việc chờ phản hồi từ cloud. Quan trọng không kém, nó cũng **bảo toàn quyền riêng tư** – điểm yếu cố hữu của mô hình cloud (dữ liệu nhạy cảm di chuyển qua mạng). Trong bối cảnh các quy định về dữ liệu ngày càng chặt (như GDPR), một giải pháp AI biên hoàn toàn cục bộ như thế này có giá trị thực tiễn rất cao.

* **So với các phương pháp học liên tục hiện có:** Lĩnh vực **Continual Learning** truyền thống đã đề xuất nhiều kỹ thuật giảm quên (như Elastic Weight Consolidation, GEM, Experience Replay, v.v.). Tuy nhiên, **hầu hết đòi hỏi bộ nhớ hoặc tài nguyên bổ sung** – ví dụ EWC cần lưu ma trận Fisher lớn, replay buffer cần lưu dữ liệu cũ, hoặc một số phương pháp thêm mạng con cho từng tác vụ làm mô hình phình to[\[17\]](https://arxiv.org/html/2505.11998v3#:~:text=%28e.g.%2C%20%5Bkirkpatrick2017overcoming%5D%29%20and%20parameter,both%20economically%20and%20environmentally%20infeasible). Những giải pháp đó khó áp dụng trực tiếp trên thiết bị biên do giới hạn bộ nhớ và điện năng. SOTA gần đây chuyển hướng sang **Parameter-Efficient CL** (sử dụng adapter như LoRA, hoặc prompt tuning) để giảm tài nguyên, nhưng nhiều nghiên cứu mới chỉ thử nghiệm trên mô hình lớn (như ViT, BERT) với pretrain có sẵn, chưa phải trong môi trường IoT real-time. Kiến trúc M.A.R.S Eternal v3 kế thừa ý tưởng **hiệu quả tham số** đó và tiến xa hơn: chúng tôi kết hợp thêm HDC memory và data distillation để **loại bỏ hoàn toàn nhu cầu lưu trữ dữ liệu gốc hoặc mô hình phụ cồng kềnh**, đồng thời vẫn đạt hiệu quả chống quên tương đương hoặc tốt hơn. Chẳng hạn, PEARL (2025) dùng LoRA động cho CL thị giác cho thấy hiệu quả vượt trội so với CL truyền thống ngay cả **không cần buffer hồi tưởng**[\[8\]](https://arxiv.org/html/2505.11998v3#:~:text=knowledge%20in%20pre,ResNet%2C%20Separable). Kiến trúc của chúng tôi áp dụng triết lý tương tự trong bối cảnh biên, cho phép **học nhiều nhiệm vụ liên tiếp mà không cần mở rộng mô hình vô hạn** (nhờ quản lý adapter và memory thông minh).

* **So với LifeHD (HDC lifelong learning):** LifeHD (ACM SenSys 2023\) là hệ thống tiên phong dùng HDC cho học suốt đời trên thiết bị edge, đạt kết quả ấn tượng trong môi trường **không giám sát**[\[4\]](https://arxiv.org/html/2403.04759v1#:~:text=perform%20extensive%20evaluations%20across%20three,com%2FOrienfish%2FLifeHD). Tuy nhiên, LifeHD chủ yếu tập trung vào **clustering unsupervised** và chưa kết hợp với mô hình deep learning truyền thống, cũng như chưa có thành phần suy luận nhân quả hay thích ứng test-time. Kiến trúc M.A.R.S Eternal v3 có thể xem là thế hệ kế tiếp: **phổ quát hơn**, kết hợp HDC với mạng neural nên áp dụng được cho cả bài toán có giám sát (phân loại, phát hiện, dự đoán liên tục) chứ không chỉ phân cụm. Đồng thời, chúng tôi bổ sung các module (adapter, causal, TTA) khiến hệ thống toàn diện hơn so với LifeHD. Dù LifeHD đạt hiệu năng cao về cụm dữ liệu và năng lượng, kiến trúc mới kỳ vọng sẽ **vượt trội trong các tác vụ phức tạp hơn** (ví dụ nhận dạng nhiều lớp, xử lý chuỗi thời gian có quan hệ nhân quả) nhờ khai thác những tiến bộ đa hướng từ cộng đồng AI.

* **So với TinyTTA và các phương pháp thích ứng nhanh:** TinyTTA (NeurIPS 2024\) là SOTA về test-time adaptation trên thiết bị hạn chế, nhưng nó chỉ giải quyết **bài toán thích ứng phân phối tạm thời** chứ không thực sự học kiến thức mới lâu dài. Hơn nữa, TinyTTA chủ yếu nhằm khắc phục domain shift trong cùng một tác vụ (ví dụ cùng là phân loại, nhưng dữ liệu test khác domain dữ liệu train). Kiến trúc của chúng tôi tích hợp hẳn TTA như một thành phần, do đó **đương nhiên đạt được hiệu năng ngang tầm TinyTTA** trong việc thích ứng online (vì kế thừa các kỹ thuật cốt lõi như ensemble exit, batch-agnostic update). Tuy nhiên, chúng tôi **đi xa hơn TTA**: hệ thống không chỉ thích ứng tạm thời mà còn **học hẳn** nếu sự thay đổi là dài hạn. Ví dụ, nếu camera bị mờ vĩnh viễn, TTA đơn thuần sẽ phải thích ứng lại mỗi lần, còn hệ thống của chúng tôi sẽ học cập nhật trọng số (qua HDC/adapter) để thích nghi dài hạn. Về độ phức tạp, TinyTTA đã chứng minh có thể chạy được trên MCU 512KB[\[13\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=Moreover%2C%20we%20develop%20the%20TinyTTA,devices%2C%20such%20as%20microcontroller%20units), do đó việc tích hợp TTA vào kiến trúc lớn hơn vẫn khả thi. So với SOTA thích ứng nhanh khác (Tent, EATA, v.v.), giải pháp của chúng tôi có thêm **chiều kích nhân quả**: không chỉ điều chỉnh phân phối đơn thuần mà còn **hiểu tại sao phân phối thay đổi**, nhờ đó xử lý triệt để hơn các nguyên nhân gây shift (ví dụ phân biệt shift do lỗi cảm biến hay do thay đổi thực sự trong môi trường).

* **So với các nghiên cứu suy luận nhân quả:** Hiện tại, hướng tích hợp học sâu với suy luận nhân quả còn khá mới. Một số SOTA (như DyC-STG 2025\) đã bắt đầu **kết hợp mô hình đồ thị động với reasoning nhân quả** trong bài toán IoT cụ thể và thu được kết quả khả quan (F1 \~0.93, cao hơn baseline \~1.4%[\[22\]](https://arxiv.org/html/2509.06483v1#:~:text=representations%20by%20strictly%20enforcing%20temporal,Score%20of%20up%20to%200.930)). Tuy vậy, nhiều phương pháp nhân quả hiện tại vẫn tách rời khỏi mạng học sâu chính (thường học đồ thị nhân quả offline rồi mới áp dụng). Kiến trúc M.A.R.S Eternal v3 **mang tính tích hợp sâu**: mô-đun nhân quả được thiết kế *end-to-end* cùng mạng neural và cập nhật liên tục từ dữ liệu streaming. Nhờ vậy, nó tránh được hạn chế SOTA thường gặp – ví dụ một số phương pháp discovery nhân quả đòi hỏi giả định thống kê mạnh và không gắn liền với biểu diễn nội tại của mô hình[\[11\]](https://arxiv.org/html/2509.06483v1#:~:text=that%20evolve%20based%20on%20data,lack%20of%20a%20unified%20framework). Kiến trúc của chúng tôi lấp vào khoảng trống khi **chưa có khung thống nhất kết hợp chặt chẽ đồ thị động sự kiện với suy luận nhân quả bên trong mạng**[\[23\]](https://arxiv.org/html/2509.06483v1#:~:text=explicit%20causal%20discovery%2C%20attempting%20to,reasoning%20embedded%20within%20the%20architecture). Nói cách khác, so với hiện trạng manh mún (mỗi phương pháp giải quyết một phần: cái thì dynamic graph, cái thì causal inference, cái thì continual learning), M.A.R.S Eternal v3 **đề xuất một giải pháp hợp nhất tất cả trong một hệ thống**.

Với những so sánh trên, có thể thấy kiến trúc đề xuất không chỉ **theo kịp** các tiến bộ SOTA ở từng khía cạnh (hiệu năng edge, continual learning, test-time adaptation, causal reasoning) mà còn **vượt lên dẫn đầu** bằng cách phối hợp chúng để khắc phục nhược điểm lẫn nhau. Đây là cách tiếp cận đột phá hướng tới AI biên toàn năng, khác biệt rõ rệt so với các giải pháp hiện hành vốn chỉ tập trung giải quyết một mặt của vấn đề.

## Đề xuất triển khai thực tế

Để hiện thực hóa kiến trúc M.A.R.S Eternal v3 trong bối cảnh ứng dụng thực tế (ví dụ một hệ thống IoT công nghiệp, xe tự hành hoặc mạng cảm biến thông minh), lộ trình triển khai có thể bao gồm các bước sau:

1. **Lựa chọn phần cứng và nền tảng phù hợp:** Dựa trên yêu cầu tác vụ và ngân sách tài nguyên, đội ngũ phát triển cần chọn thiết bị biên có hiệu suất vừa đủ. Kiến trúc linh hoạt có thể chạy trên nhiều cấp độ phần cứng:

2. Với những ứng dụng cực kỳ hạn chế (ví dụ cảm biến mini, wearable IoT), có thể triển khai trên **vi điều khiển (MCU)**. Thành phần mô hình nền sẽ là một mạng rất nhỏ (vài chục nghìn tham số), engine TTA và các thuật toán HDC, distillation sẽ được cài đặt bằng C/C++ tối ưu. TinyTTA Engine đã chứng minh chạy được trên MCU STM32H7 chỉ 512KB RAM[\[13\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=Moreover%2C%20we%20develop%20the%20TinyTTA,devices%2C%20such%20as%20microcontroller%20units), và LifeHD cũng chạy trên Raspberry Pi Zero, điều này chứng tỏ tính khả thi. Dĩ nhiên, trên MCU mức độ phức tạp của mô hình phải giản lược: ví dụ có thể **ưu tiên HDC nhiều hơn** (vì HDC chủ yếu XOR và đếm bit, rất nhẹ) và **giảm bớt mạng neural sâu**.

3. Với những hệ thống cao cấp hơn (xe tự hành, robot di động, gateway IoT công nghiệp), có thể dùng **SoC mạnh hơn** như NVIDIA Jetson, Google Coral, Raspberry Pi 4... Các nền tảng này có CPU ARM nhiều nhân, đôi khi có GPU hoặc TPU, cho phép chạy mạng neural phức tạp hơn (thậm chí triển khai một mô hình CNN hay Transformer nhỏ). Trên các thiết bị này, **mọi thành phần kiến trúc đều có thể kích hoạt đầy đủ**. Ví dụ LifeHD đã triển khai trên Jetson TX2 và Pi 4, đo được cải thiện lớn về độ chính xác và hiệu năng[\[24\]](https://arxiv.org/html/2403.04759v1#:~:text=additionally%20propose%20two%20variants%20of,com%2FOrienfish%2FLifeHD). Những bo mạch như Jetson cũng thuận lợi cho việc chạy các library machine learning (PyTorch, TensorRT) để tăng tốc suy luận.

4. **Phát triển mô hình nền và bộ điều hợp:** Trước tiên, một mô hình nền ban đầu cần được huấn luyện (có thể thực hiện offline trên dữ liệu mô phỏng hoặc dữ liệu lịch sử) để thực hiện tốt các nhiệm vụ chính yếu. Ví dụ, với xe tự hành, mô hình nền có thể được pre-train để nhận dạng biển báo giao thông, phân biệt làn đường, v.v. Quá trình huấn luyện này nên tận dụng các kỹ thuật **knowledge distillation** để nén mô hình đến kích thước phù hợp thiết bị. Sau khi có mô hình nền, chuẩn bị các **adapter/LoRA**: xác định trước các điểm chèn adapter (thường vào mỗi layer chính của mạng) và khởi tạo chúng. Hệ thống cũng cần định trước “phân vùng” tài nguyên cho adapter (ví dụ tổng số tham số adapter được phép, hoặc rank tối đa). Với cơ chế **dynamic LoRA**, có thể tích hợp thuật toán tự động quyết định rank dựa trên độ mới của tác vụ (như PEARL đã làm[\[25\]](https://arxiv.org/html/2505.11998v3#:~:text=resource%20allocation%20and%20performance,baselines%20by%20a%20large%20margin)).

5. **Triển khai bộ nhớ HDC và kho data distillation:** Lựa chọn chiến lược mã hóa HDC cho phù hợp dữ liệu. Nếu dữ liệu là chuỗi tín hiệu, có thể dùng phương pháp bundling/thêm pha trong HDC; nếu là hình ảnh, cần có bộ encoder ảnh sang hypervector (có thể train một autoencoder nhỏ để tạo HV từ ảnh). Triển khai cấu trúc bộ nhớ hai tầng: một vùng **bộ nhớ làm việc (working memory)** dung lượng nhỏ, tốc độ truy cập nhanh, và một **bộ nhớ dài hạn (long-term memory)** dung lượng lớn hơn lưu các hypervector trọng yếu[\[26\]](https://arxiv.org/html/2403.04759v1#:~:text=When%20reaching%20its%20size%20limit,term%20memory). Lập trình các thuật toán cập nhật HV như trong LifeHD: thêm HV mới, hợp nhất nếu trùng, loại bỏ HV cũ theo LRU khi đầy[\[15\]](https://arxiv.org/html/2403.04759v1#:~:text=When%20reaching%20its%20size%20limit,term%20memory)[\[14\]](https://arxiv.org/html/2403.04759v1#:~:text=match%20at%20L586%20consolidated%20to,term%20memory). Song song, thiết kế thành phần **dataset distillation**: có thể tích hợp một mô-đun nhỏ sử dụng phương pháp tối ưu (như gradient matching hoặc meta-learning) để tạo mẫu tổng hợp. Do việc chưng cất dữ liệu có thể tốn thời gian, ta có thể thực hiện nó **dưới nền vào lúc thiết bị rảnh** (ví dụ ban đêm hoặc khi CPU idle). Kết quả distilled sẽ lưu vào flash của thiết bị để dùng khi cần rehearsal.

6. **Tích hợp module nhân quả:** Tùy ứng dụng, xây dựng **kiến thức nhân quả tiên nghiệm** dưới dạng đồ thị hoặc luật để tích hợp ban đầu. Ví dụ, trong nhà máy, ta biết cảm biến nhiệt độ tăng thì quạt phải bật mạnh hơn (A gây B). Những hiểu biết này có thể mã hóa thành một đồ thị nhân quả sơ bộ. Triển khai mô-đun NCM (Neural Causal Model) dựa trên cấu trúc đó: mỗi quan hệ nhân quả có thể gắn một mạng nhỏ ước lượng hiệu ứng. Đồng thời cho mô đun này **quan sát đầu vào và đầu ra của mô hình nền** để học dần các mối liên hệ. Cài đặt chức năng giám sát: khi mô hình nền đưa ra quyết định quan trọng, mô-đun nhân quả sẽ đánh giá quyết định đó dựa trên dữ liệu hiện tại và quan hệ nhân quả. Nếu phát hiện mâu thuẫn lớn (ví dụ mô hình dự đoán một hiện tượng mà theo causal model là vô lý) thì có thể cảnh báo hoặc điều chỉnh. Một lựa chọn khác là thiết kế **loss kết hợp nhân quả**: khi huấn luyện hoặc update mô hình nền, thêm một thành phần loss phạt nếu mô hình vi phạm quan hệ nhân quả đã biết. Cách này giúp nhúng kiến thức nhân quả vào chính biểu diễn của mạng.

7. **Xây dựng engine thích ứng thời gian thực:** Trên phần cứng mục tiêu, hiện thực các thuật toán TTA sao cho tối ưu bộ nhớ. Có thể sử dụng các thư viện tối ưu học online nếu có, hoặc tự cài đặt. Chẳng hạn, code TinyTTA Engine (nếu được công bố) có thể tích hợp để quản lý quá trình early-exit và ensemble. Cấu hình các tham số như khoảng thời gian giữa các lần cập nhật, độ lớn batch tạm (nếu batch=1 thì dùng kỹ thuật batch-agnostic như TinyTTA đề xuất[\[27\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=TTA%20on%20constrained%20devices%20with,with%20small%20batch%20sizes%20for)). Đảm bảo rằng khối TTA có thể bật/tắt linh hoạt để không ảnh hưởng khi không cần thiết. Cũng nên đặt giới hạn để tránh TTA cập nhật làm trôi mô hình nếu môi trường dao động liên tục (có thể đặt ngưỡng độ lệch phân phối để quyết định khi nào chạy TTA).

8. **Kiểm thử tích hợp và tinh chỉnh:** Khi mọi thành phần đã có, tiến hành tích hợp toàn hệ thống và chạy thử trong môi trường giả lập trước. Theo dõi log để xem các thành phần có hoạt động hài hòa không: ví dụ, khi thêm adapter mới có gây xung đột tài nguyên? Tốc độ cập nhật HDC có kịp thời gian thực không? TTA chạy có làm trễ suy luận vượt ngưỡng cho phép không?... Dựa trên kết quả, tinh chỉnh tham số: có thể giảm tần suất TTA nếu trễ cao, hoặc tăng kích thước working memory nếu thấy hệ thống quên nhanh hơn mong muốn, v.v. Đặc biệt chú ý đến **tiêu thụ năng lượng** nếu chạy trên pin: bật các module ở chế độ thích ứng (adaptive) để chỉ chạy khi cần thiết (ví dụ causal reasoning có thể không chạy mỗi mẫu, mà chỉ khi phát hiện sự kiện bất thường để tiết kiệm điện).

9. **Triển khai thực tế và giám sát lâu dài:** Đưa hệ thống lên thiết bị thật và gắn vào ứng dụng mục tiêu (xe, nhà thông minh, dây chuyền sản xuất...). Trong giai đoạn đầu, kích hoạt chế độ **giám sát**: hệ thống log lại các trường hợp quyết định quan trọng, các lần cập nhật trọng số, v.v. để nhóm phát triển theo dõi. Điều này giúp phát hiện nếu có vấn đề như **quên âm thầm** (silent forgetting) – khi mô hình quên kiến thức cũ mà không có cảnh báo rõ. Nếu xảy ra, có thể cần điều chỉnh lại trọng số regularization (tăng phạt quên) hoặc bổ sung mẫu distilled cho nhiệm vụ cũ. Hệ thống cũng nên có cơ chế fail-safe: ví dụ nếu phát hiện mô hình suy giảm dưới ngưỡng ở một nhiệm vụ quan trọng, có thể tạm **dừng học liên tục** và báo hiệu cần bảo trì. Qua thời gian, khi đã ổn định, hệ thống sẽ tự vận hành.

10. **Cập nhật và mở rộng:** Mặc dù kiến trúc hướng đến hoạt động độc lập, chu kỳ **cải tiến phần mềm** vẫn nên diễn ra. Dựa trên dữ liệu log thu thập, ta có thể đào tạo offline một phiên bản mô hình nền mới tốt hơn (tận dụng toàn bộ dữ liệu mà thiết bị đã trải qua, bằng cách hợp nhất các HV và distilled data). Sau đó, phát hành bản cập nhật mô hình nền đó tới thiết bị (qua OTA \- over the air nếu có mạng). Thiết bị sẽ tích hợp mô hình mới làm nền và tiếp tục học liên tục. Kiểu cập nhật định kỳ này đảm bảo **không tích lũy lỗi** qua thời gian và tận dụng được khả năng tính toán mạnh ở server tập trung nếu cần, nhưng vẫn giữ triết lý **học phần lớn tại biên** (vì tần suất cập nhật rất thưa, ví dụ vài tháng một lần).

**Khả năng triển khai thực tế:** Với lộ trình trên, kiến trúc M.A.R.S Eternal v3 có thể ứng dụng trong nhiều lĩnh vực. Ví dụ, trên một **xe tự hành**, hệ thống sẽ cho phép xe tự học các điều kiện đường sá mới (đường núi, đường ngập nước...), tự phát hiện và ghi nhớ các biển báo địa phương hay vật cản lạ. Quan trọng là xe có thể **thích ứng ngay cả khi mất kết nối 5G**, đảm bảo an toàn liên tục. Trong **nhà máy thông minh**, các cảm biến trang bị kiến trúc này sẽ liên tục tối ưu hóa phát hiện lỗi máy móc: chúng học dần về rung động hay âm thanh bất thường theo thời gian, giảm phụ thuộc hoàn toàn vào mô hình được lập trình sẵn ban đầu. **Y tế cá nhân** cũng là mảnh đất ứng dụng: thiết bị đeo của bệnh nhân có AI này sẽ hiểu dần tình trạng riêng của từng người (tiếng tim, bước đi, thói quen sinh hoạt) và điều chỉnh cảnh báo phù hợp, trong khi dữ liệu nhạy cảm không hề rời khỏi thiết bị của bệnh nhân.

Tóm lại, kiến trúc AI tối thượng M.A.R.S Eternal v3 hoàn toàn khả thi để triển khai thực tiễn nhờ sự hỗ trợ của các tiến bộ mới nhất (nhiều cái đã có mã nguồn mở và demo trên phần cứng cụ thể). Chìa khóa thành công là **thiết kế đồng bộ phần cứng-phần mềm**, lợi dụng tối đa năng lực thiết bị, và một chiến lược cập nhật thận trọng để duy trì ổn định. Với việc triển khai thành công, chúng ta sẽ có một thế hệ thiết bị biên thông minh có thể **tự học hỏi và thích nghi vĩnh cửu**, làm nền tảng cho IoT và hệ thống tự trị trong tương lai.

**Nguồn tham khảo:**

1. Xiaofan Yu *et al.* (2023). “Lifelong Intelligence Beyond the Edge using Hyperdimensional Computing.” *arXiv preprint arXiv:2403.04759* [\[3\]](https://arxiv.org/html/2403.04759v1#:~:text=organization%20to%20intelligently%20store%20and,Our%20code%20is%20available%20at)[\[4\]](https://arxiv.org/html/2403.04759v1#:~:text=perform%20extensive%20evaluations%20across%20three,com%2FOrienfish%2FLifeHD)

2. Tao Feng *et al.* (2025). “ZeroFlow: Overcoming Catastrophic Forgetting is Easier than You Think.” *arXiv preprint arXiv:2501.01045* [\[6\]](https://arxiv.org/html/2501.01045v4#:~:text=hardware%20constraints%2C%20or%20non,new%20enhancements%20that%20further%20improve)

3. Prashant Bhat *et al.* (2025). “Parameter Efficient Continual Learning with Dynamic Low-Rank Adaptation (PEARL).” *arXiv preprint arXiv:2505.11998* [\[8\]](https://arxiv.org/html/2505.11998v3#:~:text=knowledge%20in%20pre,ResNet%2C%20Separable)[\[17\]](https://arxiv.org/html/2505.11998v3#:~:text=%28e.g.%2C%20%5Bkirkpatrick2017overcoming%5D%29%20and%20parameter,both%20economically%20and%20environmentally%20infeasible)

4. Alex Lewandowski *et al.* (2025). “Learning Continually by Spectral Regularization.” *ICLR 2025 (Poster)* [\[18\]](https://openreview.net/forum?id=Hcb2cgPbMg#:~:text=continual%20learning%20inspired%20by%20the,We%20present%20an%20experimental)[\[19\]](https://openreview.net/forum?id=Hcb2cgPbMg#:~:text=beneficial%20initialization%20properties%20throughout%20training,demonstrating%20better%20training%20in%20individual)

5. Hong Jia *et al.* (2024). “TinyTTA: Efficient Test-Time Adaptation via Early-Exit Ensembles on Edge Devices.” *NeurIPS 2024* [\[12\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=sizes,with%20small%20batch%20sizes%20for)[\[13\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=Moreover%2C%20we%20develop%20the%20TinyTTA,devices%2C%20such%20as%20microcontroller%20units)

6. Songze Li *et al.* (2024). “Continual Learning with Knowledge Distillation: A Survey.” *TechRxiv preprint* [\[5\]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/#:~:text=,2022)

7. Ziqi Liu *et al.* (2025). “DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data Credibility Analysis in IoT.” *arXiv preprint arXiv:2509.06483* [\[11\]](https://arxiv.org/html/2509.06483v1#:~:text=that%20evolve%20based%20on%20data,lack%20of%20a%20unified%20framework)[\[23\]](https://arxiv.org/html/2509.06483v1#:~:text=explicit%20causal%20discovery%2C%20attempting%20to,reasoning%20embedded%20within%20the%20architecture)

8. Emergent Mind (2025). “Neural Causal Models: Bridging Neural Networks and Causality.” *EmergentMind Topic* [\[9\]](https://www.emergentmind.com/topics/neural-causal-models-ncms#:~:text=typically%20feedforward%20multilayer%20perceptrons,and%20empirical%20results%20regarding%20NCMs)

---

[\[1\]](https://arxiv.org/html/2403.04759v1#:~:text=On,and%20lightweight%20learning%20paradigm%20called) [\[2\]](https://arxiv.org/html/2403.04759v1#:~:text=To%20fundamentally%20address%20these%20issues%2C,representing%20the%20future%20of%20IoT) [\[3\]](https://arxiv.org/html/2403.04759v1#:~:text=organization%20to%20intelligently%20store%20and,Our%20code%20is%20available%20at) [\[4\]](https://arxiv.org/html/2403.04759v1#:~:text=perform%20extensive%20evaluations%20across%20three,com%2FOrienfish%2FLifeHD) [\[14\]](https://arxiv.org/html/2403.04759v1#:~:text=match%20at%20L586%20consolidated%20to,term%20memory) [\[15\]](https://arxiv.org/html/2403.04759v1#:~:text=When%20reaching%20its%20size%20limit,term%20memory) [\[20\]](https://arxiv.org/html/2403.04759v1#:~:text=and%20Peng%2C%202022%20%29,adaptability%20to%20accommodate%20new%20environments) [\[21\]](https://arxiv.org/html/2403.04759v1#:~:text=cities%C2%A0%28Chen%20et%C2%A0al,only) [\[24\]](https://arxiv.org/html/2403.04759v1#:~:text=additionally%20propose%20two%20variants%20of,com%2FOrienfish%2FLifeHD) [\[26\]](https://arxiv.org/html/2403.04759v1#:~:text=When%20reaching%20its%20size%20limit,term%20memory) Lifelong Intelligence Beyond the Edge using Hyperdimensional Computing

[https://arxiv.org/html/2403.04759v1](https://arxiv.org/html/2403.04759v1)

[\[5\]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/#:~:text=,2022) [\[16\]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/#:~:text=performance%20while%20offering%20significant%20efficiency,discuss%20the%20significance%20of%20distillation)  Knowledge distillation and dataset distillation of large language models: emerging trends, challenges, and future directions \- PMC 

[https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12634706/)

[\[6\]](https://arxiv.org/html/2501.01045v4#:~:text=hardware%20constraints%2C%20or%20non,new%20enhancements%20that%20further%20improve) ZeroFlow: Overcoming Catastrophic Forgetting is Easier than You Think

[https://arxiv.org/html/2501.01045v4](https://arxiv.org/html/2501.01045v4)

[\[7\]](https://arxiv.org/html/2505.11998v3#:~:text=Catastrophic%20forgetting%20has%20remained%20a,dynamic%20rank%20allocation%20for%20LoRA) [\[8\]](https://arxiv.org/html/2505.11998v3#:~:text=knowledge%20in%20pre,ResNet%2C%20Separable) [\[17\]](https://arxiv.org/html/2505.11998v3#:~:text=%28e.g.%2C%20%5Bkirkpatrick2017overcoming%5D%29%20and%20parameter,both%20economically%20and%20environmentally%20infeasible) [\[25\]](https://arxiv.org/html/2505.11998v3#:~:text=resource%20allocation%20and%20performance,baselines%20by%20a%20large%20margin) Parameter Efficient Continual Learning with Dynamic Low-Rank Adaptation

[https://arxiv.org/html/2505.11998v3](https://arxiv.org/html/2505.11998v3)

[\[9\]](https://www.emergentmind.com/topics/neural-causal-models-ncms#:~:text=typically%20feedforward%20multilayer%20perceptrons,and%20empirical%20results%20regarding%20NCMs) Neural Causal Models: Bridging Neural Networks and Causality

[https://www.emergentmind.com/topics/neural-causal-models-ncms](https://www.emergentmind.com/topics/neural-causal-models-ncms)

[\[10\]](https://arxiv.org/html/2509.06483v1#:~:text=smart%20home%2C%20a%20single%20human,robustness%2C%20making%20it%20liable%20to) [\[11\]](https://arxiv.org/html/2509.06483v1#:~:text=that%20evolve%20based%20on%20data,lack%20of%20a%20unified%20framework) [\[22\]](https://arxiv.org/html/2509.06483v1#:~:text=representations%20by%20strictly%20enforcing%20temporal,Score%20of%20up%20to%200.930) [\[23\]](https://arxiv.org/html/2509.06483v1#:~:text=explicit%20causal%20discovery%2C%20attempting%20to,reasoning%20embedded%20within%20the%20architecture) DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data Credibility Analysis in IoT

[https://arxiv.org/html/2509.06483v1](https://arxiv.org/html/2509.06483v1)

[\[12\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=sizes,with%20small%20batch%20sizes%20for) [\[13\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=Moreover%2C%20we%20develop%20the%20TinyTTA,devices%2C%20such%20as%20microcontroller%20units) [\[27\]](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf#:~:text=TTA%20on%20constrained%20devices%20with,with%20small%20batch%20sizes%20for) proceedings.neurips.cc

[https://proceedings.neurips.cc/paper\_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2024/file/4c454d34f3a4c8d6b4ca85a918e5d7ba-Paper-Conference.pdf)

[\[18\]](https://openreview.net/forum?id=Hcb2cgPbMg#:~:text=continual%20learning%20inspired%20by%20the,We%20present%20an%20experimental) [\[19\]](https://openreview.net/forum?id=Hcb2cgPbMg#:~:text=beneficial%20initialization%20properties%20throughout%20training,demonstrating%20better%20training%20in%20individual) Learning Continually by Spectral Regularization | OpenReview

[https://openreview.net/forum?id=Hcb2cgPbMg](https://openreview.net/forum?id=Hcb2cgPbMg)